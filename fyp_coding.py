# -*- coding: utf-8 -*-
"""FYP Coding

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1drAWMdssvulgoggi6_T0m9v9jAYE3LaS
"""

import pandas as pd

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv("/content/drive/MyDrive/FYP/FYP.csv", encoding='latin-1')
# encoding='latin-1', encoding='utf-8'
df

"""Data Cleaning"""

# Drop rows with any missing values
df.dropna(inplace=True)

import re

def remove_urls(text):
  """
  Removes URLs from a string.
  """
  if not isinstance(text, str):
    text = str(text)
  url_pattern = r"https?://\S+"
  return re.sub(url_pattern, '', text)

df['Comment1'] = df['Comment'].apply(remove_urls)

# Define a regular expression to match unknown characters
unknown_char_regex = re.compile(r'[^a-zA-Z0-9\s\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF\U00002702-\U000027B0\U000024C2-\U0001F251]')

# Function to remove unknown characters
def remove_unknown_chars(text):
    return unknown_char_regex.sub('', str(text))

# Apply the function to the "Comment" column
df["Comment1"] = df["Comment1"].apply(lambda x: remove_unknown_chars(x))
df

import string

def remove_punctuation(text):
  """
  Removes punctuation marks, symbols, and extraneous numbers from a string.
  """
  # Define punctuation and symbols to be removed
  punctuation = string.punctuation
  symbols = "!@#$%^&*()_-+=`~,./?<>|"
  numbers = "0123456789"

  # Remove punctuation, symbols, and numbers
  text = ''.join([char for char in text if char not in punctuation + symbols + numbers])

  return text

# Apply the function to the "Content" column
df['Comment1'] = df['Comment1'].apply(remove_punctuation)
df

# Convert text column to lowercase
df['Comment1'] = df['Comment1'].str.lower()

# Remove duplicates from the entire dataset
df.drop_duplicates(inplace=True)

# Reset the index after removing duplicates
df.reset_index(drop=True, inplace=True)

df

import nltk
from nltk.corpus import stopwords

# Download stopwords if necessary
nltk.download('stopwords')

# Get the list of stopwords from NLTK
stop_words = set(stopwords.words('english'))

# Define stopwords to retain
stopwords_to_retain = {
    'not', 'no', 'never', 'none', 'neither', 'nor', 'nothing', 'nobody', 'nowhere', 'too',
    'but', 'however', 'although', 'though', 'even though', 'yet', 'still', 'despite',
    'very', 'too', 'enough', 'quite', 'rather', 'almost', 'if', 'unless', 'cant'
}

# Remove the stopwords to retain from the main stopwords list
final_stop_words = stop_words - stopwords_to_retain

def remove_stopwords(text):
    """
    Removes stopwords from a string while retaining important ones.
    """
    words = text.split()
    filtered_words = [word for word in words if word not in final_stop_words]
    return ' '.join(filtered_words)

# Apply the function to the "Comment" column
df['Comment1'] = df['Comment1'].apply(remove_stopwords)
df

"""Tokenize"""

# Download punkt tokenizer if necessary
nltk.download('punkt')

# Define a function to tokenize text
def tokenize(text):
  """
  Tokenizes a string into individual words.
  """
  tokenizer = nltk.word_tokenize(text)
  return tokenizer

# Apply the function to a column containing text
df['Comment1'] = df['Comment1'].apply(tokenize)
df

"""Lemmatize"""

from nltk.stem import WordNetLemmatizer

# Download necessary resources
nltk.download('wordnet')

# Create WordNetLemmatizer instance
lemmatizer = WordNetLemmatizer()

# Define function to lemmatize tokens
def lemmatize(tokens):
    lemmatized_tokens = []
    for token in tokens:
        lemmatized_token = None
        for pos in ['n', 'v', 'a', 'r']:
            lemmatized_token = lemmatizer.lemmatize(token, pos=pos)
            if lemmatized_token != token:
                break
        lemmatized_tokens.append(lemmatized_token)
    return ' '.join(lemmatized_tokens)

# Apply lemmatization to the tokenized column
df['lemmatized_text'] = df['Comment1'].apply(lambda x: lemmatize(x))
df

"""TextBlob"""

pip install textblob

from textblob import TextBlob

# Define custom words with their sentiment scores
custom_words = {
    # Destination related
    'beautiful': 2.0, 'scenic': 2.0, 'picturesque': 2.0, 'breathtaking': 2.0, 'boring': -2.0, 'unattractive': -2.0, 'ordinary': -1.5,
    'unsafe': -2.0, 'overrated': -2.0, 'interesting': 1.5, 'peaceful': 1.5, 'crowded': -1.5, 'dirty': -1.5, 'polluted': -2.0, 'pickpocket': -2.0,
    'mismanagement': -1.5, 'waiting': -1.5, 'decent': -1.0, 'hot': -2.0, 'rubbish': -2.0, 'stinky': -2.0, 'busy': -1.5, 'noisy': -2.0,

    # Infrastructure related
    'modern': 2.0, 'clean': 2.0, 'efficient': 2.0, 'well-maintained': 2.0, 'poor': -2.0, 'dirty': -2.0, 'dangerous': -2.0,
    'inefficient': -2.0, 'old': -1.5, 'broken': -2.0, 'convenient': 1.5, 'accessible': 1.5, 'luxurious': 2.0, 'comfortable': 1.5,
    'waste': -2.0, 'poorly': -2.0, 'overdeveloped': -2.0, 'safety': 1.5, 'shabby': -2.0,

    # Food related
    'delicious': 2.0, 'tasty': 2.0, 'flavorful': 2.0, 'authentic': 2.0, 'gourmet': 2.0, 'savory': 1.5, 'spicy': 1.5, 'too spicy': -1.5,
    'bland': -2.0, 'tasteless': -2.0, 'expensive': -2.0, 'bad': -2.0, 'unhygienic': -2.0, 'disgusting': -2.0, 'stale': -2.0, 'slow': -1.5,
    'affordable': 1.5, 'cheap': 1.5, 'fresh': 2.0, 'greasy': -1.5, 'pricey': -2.0, 'overprice': -2.0, 'overpriced': -2.0, 'over price': -2.0,
    'plain': -1.5,

    # Culture related
    'friendly': 2.0, 'welcoming': 2.0, 'religious': 1.5, 'diverse': 2.0, 'rich': 2.0, 'vibrant': 2.0, 'unfriendly': -2.0,
    'intolerant': -2.0, 'boring': -2.0, 'offensive': -2.0, 'polite': 1.5, 'helpful': 1.5, 'rude': -1.5, 'disrespectful': -2.0
}

# Define a function to adjust sentiment scores based on custom words
def custom_sentiment_analysis(text):
    blob = TextBlob(text)
    polarity = blob.sentiment.polarity

    # Adjust polarity based on custom words
    words = text.lower().split()
    for word in words:
        if word in custom_words:
            polarity += custom_words[word]

    # Determine sentiment class label (positive, negative, or neutral)
    if polarity > 0.1:
        sentiment_class = 'positive'
    elif polarity < -0.1:
        sentiment_class = 'negative'
    else:
        sentiment_class = 'neutral'

    # Normalize the polarity to match a 1-5 rating scale
    sentiment_range = round((polarity + 1) * 2.5 + 1)
    sentiment_range = max(1, min(sentiment_range, 5))

    return sentiment_class, polarity, sentiment_range

# Convert to string
df['lemmatized_text'] = df['lemmatized_text'].astype(str)

# Apply the function to each text in the dataset
df[['Sentiment_Class', 'Sentiment_Score', 'Sentiment_Range']] = df['lemmatized_text'].apply(lambda x: pd.Series(custom_sentiment_analysis(x)))

# View the updated DataFrame
df

"""VADER"""

nltk.download('vader_lexicon')
from nltk.sentiment.vader import SentimentIntensityAnalyzer

# Initialize the sentiment analyzer
sia = SentimentIntensityAnalyzer()

# Define custom words and their sentiment scores
custom_words = {
    # Destination related
    'beautiful': 2.0, 'scenic': 2.0, 'picturesque': 2.0, 'breathtaking': 2.0, 'boring': -2.0, 'unattractive': -2.0, 'ordinary': -1.5,
    'unsafe': -2.0, 'overrated': -2.0, 'interesting': 1.5, 'peaceful': 1.5, 'crowded': -1.5, 'dirty': -1.5, 'polluted': -2.0, 'pickpocket': -2.0,
    'crowded': -2.0, 'mismanagement': -1.5, 'waiting': -1.5, 'ordnary': -1.5, 'decent': -1.0, 'hot': -2.0, 'clean': 2.0, 'rubbish': -2.0, 'stinky': -2.0,
    'busy': -1.5, 'noisy': -2.0,

    # Infrastructure related
    'modern': 2.0, 'clean': 2.0, 'efficient': 2.0, 'well-maintained': 2.0, 'poor': -2.0, 'dirty': -2.0, 'dangerous': -2.0,
    'inefficient': -2.0, 'old': -1.5, 'broken': -2.0, 'crowded': -1.5, 'convenient': 1.5, 'accessible': 1.5, 'luxurious': 2.0,
    'comfortable': 1.5, 'waste': -2.0, 'poorly': -2.0, 'overdeveloped': -2.0, 'safety': 1.5, 'shabby': -2.0,

    # Food related
    'delicious': 2.0, 'tasty': 2.0, 'flavorful': 2.0, 'authentic': 2.0, 'gourmet': 2.0, 'savory': 1.5, 'spicy': 1.5, 'too spicy': -1.5,
    'bland': -2.0, 'tasteless': -2.0, 'expensive': -2.0, 'bad': -2.0, 'unhygienic': -2.0, 'disgusting': -2.0, 'stale': -2.0, 'slow': -1.5,
    'affordable': 1.5, 'cheap': 1.5, 'fresh': 2.0, 'greasy': -1.5, 'pricey': -2.0, 'overprice': -2.0, 'overpriced': -2.0,  'over price': -2.0,
    'plain': -1.5,

    # Culture related
    'friendly': 2.0, 'welcoming': 2.0, 'religious': 1.5, 'diverse': 2.0, 'rich': 2.0, 'vibrant': 2.0, 'unfriendly': -2.0,
    'intolerant': -2.0, 'boring': -2.0, 'offensive': -2.0, 'polite': 1.5, 'helpful': 1.5, 'rude': -1.5, 'disrespectful': -2.0
}

# Update VADER's lexicon with custom words
sia.lexicon.update(custom_words)

# Define a function to perform sentiment analysis
def sentiment_analysis(text):
    sentiment_scores = sia.polarity_scores(text)
    compound_score = sentiment_scores['compound']

    # sentiment class label
    if compound_score >= 0.1:
        sentiment_class = 'positive'
    elif compound_score <= -0.1:
        sentiment_class = 'negative'
    else:
        sentiment_class = 'neutral'

    # Map compound score to a range of 1-5
    sentiment_range = round((compound_score + 1) * 2.5 + 1)
    if sentiment_range < 1:
        sentiment_range = 1
    elif sentiment_range > 5:
        sentiment_range = 5

    return sentiment_class, compound_score, sentiment_range

# Convert to string
df['lemmatized_text'] = df['lemmatized_text'].astype(str)

# Apply the function to each text in the dataset
df[['Sentiment_Class', 'Sentiment_Score', 'Sentiment_Range']] = df['lemmatized_text'].apply(lambda x: pd.Series(sentiment_analysis(x)))

# View the updated DataFrame
df

"""BERT"""

# Ensure proper installation
!pip uninstall -y transformers torch accelerate
!pip install transformers[torch] torch
!pip install --upgrade accelerate

from sklearn.metrics import precision_recall_fscore_support, accuracy_score
from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback
from sklearn.model_selection import train_test_split
import torch

# Initialize the tokenizer and model
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)

# Tokenize and encode the texts
def tokenize_and_encode(texts):
    return tokenizer(texts, padding=True, truncation=True, return_tensors='pt')

# Convert sentiment classes to numeric labels
label_map = {'positive': 2, 'neutral': 1, 'negative': 0}
labels = df['Sentiment_Class'].map(label_map).values

# Split the data
train_texts, test_texts, train_labels, test_labels = train_test_split(df['lemmatized_text'].tolist(), labels, test_size=0.1, random_state=42)
train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.1, random_state=42)

# Tokenize and encode the texts
train_encodings = tokenize_and_encode(train_texts)
val_encodings = tokenize_and_encode(val_texts)
test_encodings = tokenize_and_encode(test_texts)

# Create datasets
class SentimentDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: val[idx] for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)

train_dataset = SentimentDataset(train_encodings, train_labels)
val_dataset = SentimentDataset(val_encodings, val_labels)
test_dataset = SentimentDataset(test_encodings, test_labels)

# Define training arguments
training_args = TrainingArguments(
    output_dir='./results',
    num_train_epochs=5,  # Start with 3 epochs, can increase if needed
    per_device_train_batch_size=16,  # Increase if possible
    per_device_eval_batch_size=16,
    warmup_steps=50,
    weight_decay=0.01,
    logging_dir='./logs',
    logging_steps=10,
    evaluation_strategy="epoch",
    save_strategy="epoch",  # Ensure this matches evaluation_strategy
    load_best_model_at_end=True,
    fp16=True,  # Enable mixed precision training
    save_total_limit=1,
)

# Define the compute_metrics function
def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')
    acc = accuracy_score(labels, preds)
    return {
        'accuracy': acc,
        'precision': precision,
        'recall': recall,
        'f1': f1

    }

# Initialize the Trainer with compute_metrics and early stopping
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics,
    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]  # Stop if no improvement for 3 epochs
)

# Train the model
trainer.train()

# Evaluate the model on the validation set
val_result = trainer.evaluate(eval_dataset=val_dataset)
print(f"Validation results: {val_result}")

# Evaluate the model on the test set
test_result = trainer.evaluate(eval_dataset=test_dataset)
print(f"Test results: {test_result}")

"""SVM (Percentage Split)"""

from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer

text = df['lemmatized_text'].tolist()  # Get text data as a list
labels = df['Sentiment_Class'].tolist()  # Get sentiment class labels

vectorizer = TfidfVectorizer(max_features=1000)  # Reduce dimensions (optional)
features = vectorizer.fit_transform(text)  # Generate TF-IDF features

X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)

# Choose linear kernel for simplicity (adjust as needed)
svm_model = SVC(kernel='linear')
svm_model.fit(X_train, y_train)

y_pred = svm_model.predict(X_test)
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Print various evaluation metrics
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred, average='weighted'))
print("Recall:", recall_score(y_test, y_pred, average='weighted'))
print("F1-Score:", f1_score(y_test, y_pred, average='weighted'))

"""SVM (Cross Validation)"""

from sklearn.svm import SVC
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import numpy as np

# Prepare the data
text = df['lemmatized_text'].tolist()  # Get text data as a list
labels = df['Sentiment_Class'].tolist()  # Get sentiment class labels

vectorizer = TfidfVectorizer(max_features=1000)  # Reduce dimensions (optional)
features = vectorizer.fit_transform(text)  # Generate TF-IDF features

# Convert labels to a numeric format
label_map = {'positive': 2, 'neutral': 1, 'negative': 0}
numeric_labels = np.array([label_map[label] for label in labels])

# Define the model
svm_model = SVC(kernel='linear')

# Define the k-fold cross-validation
kf = StratifiedKFold(n_splits=20)  # Change the number of splits as needed

# Initialize lists to store metrics for each fold
accuracy_scores = []
precision_scores = []
recall_scores = []
f1_scores = []

# Perform k-fold cross-validation
for train_index, test_index in kf.split(features, numeric_labels):
    X_train, X_test = features[train_index], features[test_index]
    y_train, y_test = numeric_labels[train_index], numeric_labels[test_index]

    # Train the model
    svm_model.fit(X_train, y_train)

    # Predict on the test set
    y_pred = svm_model.predict(X_test)

    # Calculate and store the metrics for this fold
    accuracy_scores.append(accuracy_score(y_test, y_pred))
    precision_scores.append(precision_score(y_test, y_pred, average='weighted'))
    recall_scores.append(recall_score(y_test, y_pred, average='weighted'))
    f1_scores.append(f1_score(y_test, y_pred, average='weighted'))

# Print the average metrics across all folds
print("Accuracy:", np.mean(accuracy_scores))
print("Precision:", np.mean(precision_scores))
print("Recall:", np.mean(recall_scores))
print("F1-Score:", np.mean(f1_scores))

"""NB (Percentage Split)"""

from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer

text = df['lemmatized_text'].tolist()  # Get text data as a list
labels = df['Sentiment_Class'].tolist()  # Get sentiment class labels

vectorizer = TfidfVectorizer(max_features=1000)  # Reduce dimensions (optional)
features = vectorizer.fit_transform(text)  # Generate TF-IDF features

X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)

#Naive Bayes model
nb_model = MultinomialNB()
nb_model.fit(X_train, y_train)

# Evaluate the model
y_pred = nb_model.predict(X_test)
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Print various evaluation metrics
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred, average='weighted'))
print("Recall:", recall_score(y_test, y_pred, average='weighted'))
print("F1-Score:", f1_score(y_test, y_pred, average='weighted'))

"""NB (Cross Validation)"""

from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import numpy as np

# Prepare the data
text = df['lemmatized_text'].tolist()  # Get text data as a list
labels = df['Sentiment_Class'].tolist()  # Get sentiment class labels

vectorizer = TfidfVectorizer(max_features=1000)  # Reduce dimensions (optional)
features = vectorizer.fit_transform(text)  # Generate TF-IDF features

# Convert labels to a numeric format
label_map = {'positive': 2, 'neutral': 1, 'negative': 0}
numeric_labels = np.array([label_map[label] for label in labels])

# Define the model
nb_model = MultinomialNB()

# Define the k-fold cross-validation
kf = StratifiedKFold(n_splits=20)  # Change the number of splits as needed

# Initialize lists to store metrics for each fold
accuracy_scores = []
precision_scores = []
recall_scores = []
f1_scores = []

# Perform k-fold cross-validation
for train_index, test_index in kf.split(features, numeric_labels):
    X_train, X_test = features[train_index], features[test_index]
    y_train, y_test = numeric_labels[train_index], numeric_labels[test_index]

    # Train the model
    nb_model.fit(X_train, y_train)

    # Predict on the test set
    y_pred = nb_model.predict(X_test)

    # Calculate and store the metrics for this fold
    accuracy_scores.append(accuracy_score(y_test, y_pred))
    precision_scores.append(precision_score(y_test, y_pred, average='weighted'))
    recall_scores.append(recall_score(y_test, y_pred, average='weighted'))
    f1_scores.append(f1_score(y_test, y_pred, average='weighted'))

# Print the average metrics across all folds
print("Accuracy:", np.mean(accuracy_scores))
print("Precision:", np.mean(precision_scores))
print("Recall:", np.mean(recall_scores))
print("F1-Score:", np.mean(f1_scores))

"""Factorize"""

import pandas as pd

# Define functions to tag reviews
def tag_destination(review):
    keywords = [
        "destination", "destinations", "location", "locations" "place","places", "spot", "spots",
        "attraction", "attractions", "city", "town", "area", "region", "regions" "village", "sightseeing",
        "beautiful", "scenic", "picturesque", "breathtaking", "popular", "nice", "wonderful", "island",
        "nature", "natural", "boring", "unattractive", "unsafe", "overrated", "paradise",
        "kuala lumpur", "george town", "penang", "langkawi", "kota kinabalu", "taiping",
        "malacca", "melaka", "johor bahru", "ipoh", "pangkor",  "pulau mabul",
        "cameron highlands", "tioman island", "genting highlands", "putrajaya",
        "borneo", "mount kinabalu", "perhentian islands", "redang island",
        "taman negara", "fraser's hill", "sepang", "labuan", "pulau sipadan"
    ]
    return 1 if any(keyword in review.lower() for keyword in keywords) else 0

def tag_infrastructure(review):
    keywords = [
        "infrastructure", "facility", "amenity", "transportation", "roads", "bridges", "hospitable", "projects"
        "airports", "airport", "railways", "transport", "public transport", "hotels", "accommodation", "resort", "ecosystem", "city", "cities",
        "modern", "modernity", "wi-fi", "Wi-Fi", "clean", "efficient", "well-maintained", "beaches", "beaches", "maintenance", "drainage",
        "poor", "poorly", "dirty", "inefficient", "old", "broken", "crowded", "overdeveloped", "safety"
    ]
    return 1 if any(keyword in review.lower() for keyword in keywords) else 0

def tag_food(review):
    keywords = [
        "food", "cuisine", "meal", "restaurant", "dining", "eatery", "street food", "flavors", "flavour"
        "dishes", "local food", "café", "delicious", "tasty", "flavor", "flavours", "flavorful", "authentic",
        "gourmet", "culinary", "savory", "spicy", "eating", "laksa", "cheap", "overpriced",
        "bland", "tasteless", "expensive", "bad", "unhygienic", "disgusting", "nasi lemak"
    ]
    return 1 if any(keyword in review.lower() for keyword in keywords) else 0

def tag_culture(review):
    keywords = [
        "culture", "cultures", "tradition", "custom", "heritage", "festival", "celebration", "ethnic", "races"
        "art", "music", "dance", "cultural event", "local customs", "history", "historical", "diverse", "people"
        "friendly", "welcoming", "religious", "diverse", "rich", "vibrant", "multireligion", "multiculturalism",
        "unfriendly", "intolerant", "boring", "offensive", "ethnicities", "muslim", "temple"
    ]
    return 1 if any(keyword in review.lower() for keyword in keywords) else 0


# Apply functions to create new columns
df['Destination'] = df['Comment1'].apply(tag_destination)
df['Infrastructure'] = df['Comment1'].apply(tag_infrastructure)
df['Food'] = df['Comment1'].apply(tag_food)
df['Culture'] = df['Comment1'].apply(tag_culture)

#Count total rows for each factor
destination_count = df['Destination'].sum()
infrastructure_count = df['Infrastructure'].sum()
food_count = df['Food'].sum()
culture_count = df['Culture'].sum()

#Print the counts
print("Total reviews tagged with Destinations:", destination_count)
print("Total reviews tagged with Infrastructure:", infrastructure_count)
print("Total reviews tagged with Food:", food_count)
print("Total reviews tagged with Culture:", culture_count)

import matplotlib.pyplot as plt

# Calculate sentiment percentages and counts based on your sentiment analysis results
positive_count = (df['Sentiment_Class'] == 'positive').sum()
negative_count = (df['Sentiment_Class'] == 'negative').sum()
neutral_count = (df['Sentiment_Class'] == 'neutral').sum()

positive_percentage = (positive_count / len(df)) * 100
negative_percentage = (negative_count / len(df)) * 100
neutral_percentage = (neutral_count / len(df)) * 100

# Data for the pie chart
labels = [
    f'Positive ({positive_count})',
    f'Negative ({negative_count})',
    f'Neutral ({neutral_count})'
]
sizes = [positive_percentage, negative_percentage, neutral_percentage]
colors = ['#66b3ff', '#ff9999', '#99ff99']  # Colors for each sentiment category
explode = (0.1, 0, 0)  # Explode the 'Positive' slice

# Create a pie chart
plt.figure(figsize=(8, 6))
plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle

# Add a title
plt.title('Sentiment Analysis Results')

# Show the pie chart
plt.show()

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt

# Generate the confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Display the confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)

# Set plot labels and title
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')

# Calculate and print various evaluation metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-Score: {f1:.4f}")

# Annotate the plot with metrics
#plt.gca().text(0.9, -0.25, f'Accuracy: {accuracy:.4f}\nPrecision: {precision:.4f}\nRecall: {recall:.4f}\nF1-Score: {f1:.4f}',
               #fontsize=10, transform=plt.gca().transAxes)

# Show the plot
plt.show()

SentiClass = df.copy()  # Create a copy of the cleaned DataFrame

SentiClass.to_csv('SentiClass.csv', index=False)  # Export to CSV without the index column

from google.colab import files
files.download('SentiClass.csv')